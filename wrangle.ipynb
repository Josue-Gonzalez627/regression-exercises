{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38da5c85-0dfd-4ae7-bfc0-cbf1571dd56f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#standard DS imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#visualization imports\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#Connect to SQL DataBase\n",
    "import env\n",
    "import wrangle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0753bdf-2d1c-41e0-8379-32327bc8f13f",
   "metadata": {},
   "source": [
    "# Exercises II Regression (acquisition and prep)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db948e90-9522-4343-abd6-025d3a9ce2f7",
   "metadata": {},
   "source": [
    "Let's set up an example scenario as perspective for our regression exercises using the Zillow dataset.\n",
    "\n",
    "As a Codeup data science graduate, you want to show off your skills to the Zillow data science team in hopes of getting an interview for a position you saw pop up on LinkedIn. You thought it might look impressive to build an end-to-end project in which you use some of their Kaggle data to predict property values using some of their available features; who knows, you might even do some feature engineering to blow them away. Your goal is to predict the values of single unit properties using the observations from 2017."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14df4ee-527e-411c-8942-0741bb6af804",
   "metadata": {},
   "source": [
    "In these exercises, you will complete the first step toward the above goal: acquire and prepare the necessary Zillow data from the zillow database in the Codeup database server."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9381abdb-c92c-4380-9c89-183df0bfe2fa",
   "metadata": {},
   "source": [
    "### 1. Acquire `bedroomcnt`, `bathroomcnt`, `calculatedfinishedsquarefeet`, `taxvaluedollarcnt`, `yearbuilt`, `taxamount`, and `fips` from the `zillow` database for all 'Single Family Residential' properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48205f6-b19b-4f0d-b977-7b91eade0b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_zillow_data():\n",
    "    '''\n",
    "    Retrieves the zillow dataframe. The MySQL query will return all columns from the customers table,\n",
    "    with the three additional columns because of the joins using their ids.\n",
    "    The check file function will assure the telco file exists and what to do if it doesn't.\n",
    "    '''\n",
    "    url = env.get_db_url('telco_churn')\n",
    "    query = '''\n",
    "    Select bathroomcnt,\n",
    "\t\tbedroomcnt,\n",
    "        calculatedfinishedsquarefeet, \n",
    "        fips,\n",
    "        taxamount,\n",
    "        taxvaluedollarcnt,\n",
    "        yearbuilt\n",
    "    FROM properties_2017\n",
    "    WHERE propertylandusetypeid = '261'\n",
    "    '''\n",
    "    \n",
    "    filename = 'zillow.csv'\n",
    "\n",
    "    #call the check_file_exists fuction \n",
    "    df = check_file_exists(filename, query, url)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7df6884-462a-4e50-ad87-924f1b80babf",
   "metadata": {},
   "source": [
    "### 2. Using your acquired Zillow data, walk through the summarization and cleaning steps in your wrangle.ipynb file like we did above. You may handle the missing values however you feel is appropriate and meaningful; remember to document your process and decisions using markdown and code commenting where helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56317018-efe1-4a63-abc7-5dea3ea92235",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a2a54e-9cfe-4eaf-aff6-f8d58ab98269",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "40eb8ac1-11a4-4afa-a3d8-f22a8fe567a2",
   "metadata": {},
   "source": [
    "### 3. Write a function to split your data into train, validate, and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002890dc-3ca7-46e5-80e6-7e4d3e90eb33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdeb1b6-bfc6-4634-a6b8-c5369f8a6da0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1140ae8b-aa14-4884-b904-3220172ca5e3",
   "metadata": {},
   "source": [
    "### 4. Store all of the necessary functions to automate your process from acquiring the data to returning a cleaned dataframe with no missing values in your wrangle.py file. Name your final function wrangle_zillow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80976a5d-968d-4ff3-a472-6b30aafe72fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22ea597-697d-4af0-a3cb-b788dfa9a94f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6cd389-392e-4e9e-bfcb-96a3fc421cfc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
